import React, { useState, useRef, useEffect } from "react";
import {
  Modal,
  ModalOverlay,
  ModalContent,
  ModalHeader,
  ModalBody,
  ModalCloseButton,
  VStack,
  Text,
  Alert,
  AlertIcon,
  Tabs,
  TabList,
  TabPanels,
  Tab,
  TabPanel,
} from "@chakra-ui/react";
import { getFileSignature, uploadImage } from "@/lib/hive/client-functions";
import { formatTime } from "@/lib/utils/timeUtils";
import VideoPlayer from "./VideoPlayer";
import VideoTimeline from "./VideoTimeline";
import ThumbnailCapture from "./ThumbnailCapture";
import VideoTrimModalFooter from "./VideoTrimModalFooter";

interface VideoTrimModalProps {
  isOpen: boolean;
  onClose: () => void;
  videoFile: File | null;
  onTrimComplete: (trimmedFile: File) => void;
  maxDuration?: number;
  canBypass?: boolean;
}

const VideoTrimModal: React.FC<VideoTrimModalProps> = ({
  isOpen,
  onClose,
  videoFile,
  onTrimComplete,
  maxDuration = 15,
  canBypass = false,
}) => {
  // Video refs and state
  const videoRef = useRef<HTMLVideoElement>(null);
  const [videoUrl, setVideoUrl] = useState<string | null>(null);
  const [duration, setDuration] = useState(0);
  const [currentTime, setCurrentTime] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);

  // Trimming state
  const [startTime, setStartTime] = useState(0);
  const [endTime, setEndTime] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);

  // UI state
  const [isDragging, setIsDragging] = useState(false);
  const [isSeeking, setIsSeeking] = useState(false);
  const [isPreviewingSlider, setIsPreviewingSlider] = useState(false);

  // Refs for throttling seeks
  const lastSeekTime = useRef(0);
  const seekTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  // Thumbnail selection states
  const [thumbnailBlob, setThumbnailBlob] = useState<Blob | null>(null);
  const [thumbnailUrl, setThumbnailUrl] = useState<string | null>(null);
  const [isGeneratingThumbnail, setIsGeneratingThumbnail] = useState(false);

  // Set up video URL when file changes
  useEffect(() => {
    console.log("üé¨ VideoTrimModal: videoFile changed", {
      hasFile: !!videoFile,
      fileName: videoFile?.name,
      fileSize: videoFile?.size,
      fileType: videoFile?.type,
    });

    if (videoFile) {
      const url = URL.createObjectURL(videoFile);
      console.log("üîó Created blob URL:", url);
      setVideoUrl(url);

      return () => {
        console.log("üßπ Cleaning up blob URL:", url);
        URL.revokeObjectURL(url);
      };
    } else {
      console.log("‚ùå No video file, clearing URL");
      setVideoUrl(null);
    }
  }, [videoFile]);

  // Handle video metadata loaded
  const handleLoadedMetadata = () => {
    console.log("üìä Video metadata loaded");
    if (videoRef.current) {
      const videoDuration = videoRef.current.duration;
      console.log("‚è±Ô∏è Video duration:", videoDuration);
      setDuration(videoDuration);
      setEndTime(Math.min(videoDuration, maxDuration));
      setCurrentTime(0);
      console.log("üéØ Set endTime to:", Math.min(videoDuration, maxDuration));
    }
  };

  // Handle time updates during playback
  const handleTimeUpdate = () => {
    if (videoRef.current && !isDragging && !isSeeking) {
      const newTime = videoRef.current.currentTime;
      setCurrentTime(newTime);

      // Auto-pause when reaching end of selection during playback
      if (isPlaying && newTime >= endTime) {
        console.log("‚è∏Ô∏è Auto-pausing at end of selection");
        videoRef.current.pause();
        setIsPlaying(false);
        seekTo(startTime);
      }
    }
  };

  // Play/pause controls
  const togglePlayPause = () => {
    console.log("üéÆ Toggle play/pause, currently playing:", isPlaying);
    if (videoRef.current) {
      if (isPlaying) {
        videoRef.current.pause();
        setIsPlaying(false);
      } else {
        videoRef.current
          .play()
          .then(() => {
            console.log("‚ñ∂Ô∏è Video started playing");
            setIsPlaying(true);
          })
          .catch((error) => {
            console.error("‚ùå Failed to play video:", error);
            setIsPlaying(false);
          });
      }
    }
  };

  // Seek to specific time
  const seekTo = (time: number) => {
    if (isSeeking || isDragging || !videoRef.current) {
      return;
    }

    const video = videoRef.current;
    if (video.readyState < 2) {
      console.log(
        "‚ö†Ô∏è Video not ready for seeking, readyState:",
        video.readyState
      );
      return;
    }

    const currentTime = video.currentTime;
    if (Math.abs(currentTime - time) < 0.1) {
      return;
    }

    const now = Date.now();
    if (now - lastSeekTime.current < 100) {
      if (seekTimeoutRef.current) {
        clearTimeout(seekTimeoutRef.current);
      }
      seekTimeoutRef.current = setTimeout(() => {
        if (videoRef.current) {
          console.log("üéØ Delayed seek to:", time);
          videoRef.current.currentTime = time;
          setCurrentTime(time);
          lastSeekTime.current = Date.now();
        }
        seekTimeoutRef.current = null;
      }, 50);
      return;
    }

    console.log("üéØ Seeking to:", time);
    setIsSeeking(true);
    video.currentTime = time;
    setCurrentTime(time);
    lastSeekTime.current = now;

    const handleSeeked = () => {
      console.log("‚úÖ Seek completed");
      setIsSeeking(false);
      video.removeEventListener("seeked", handleSeeked);
    };

    video.addEventListener("seeked", handleSeeked);

    setTimeout(() => {
      if (video.readyState >= 2) {
        setIsSeeking(false);
        video.removeEventListener("seeked", handleSeeked);
      }
    }, 1000);
  };

  // Play the selected segment for preview
  const playSelection = () => {
    console.log("üé¨ Playing selection from", startTime, "to", endTime);
    if (videoRef.current) {
      seekTo(startTime);

      setTimeout(() => {
        if (videoRef.current) {
          videoRef.current
            .play()
            .then(() => {
              setIsPlaying(true);
            })
            .catch((error) => {
              console.error("Failed to play video:", error);
              setIsPlaying(false);
            });
        }
      }, 50);
    }
  };

  // Generate thumbnail from current video position and upload to Hive.blog
  const generateThumbnail = async () => {
    if (!videoRef.current) {
      console.log("‚ùå No video ref for thumbnail generation");
      return null;
    }

    console.log("üì∏ Starting thumbnail generation...");
    setIsGeneratingThumbnail(true);

    try {
      const video = videoRef.current;
      console.log(
        "üé• Video dimensions:",
        video.videoWidth,
        "x",
        video.videoHeight
      );
      console.log("üïê Current video time:", video.currentTime);

      const canvas = document.createElement("canvas");
      const ctx = canvas.getContext("2d");

      if (!ctx) {
        console.error("‚ùå Could not get canvas context");
        setIsGeneratingThumbnail(false);
        return null;
      }

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const blob = await new Promise<Blob>((resolve) => {
        canvas.toBlob(
          (blob) => {
            console.log("üñºÔ∏è Canvas blob created, size:", blob?.size);
            resolve(blob!);
          },
          "image/jpeg",
          0.9
        );
      });

      setThumbnailBlob(blob);
      console.log("üíæ Thumbnail blob set");

      const thumbnailFile = new File([blob], "thumbnail.jpg", {
        type: "image/jpeg",
      });
      console.log(
        "üìÅ Thumbnail file created:",
        thumbnailFile.name,
        thumbnailFile.size
      );

      console.log("üîê Getting file signature...");
      const signature = await getFileSignature(thumbnailFile);
      console.log("‚úÖ Got signature:", signature);

      console.log("‚òÅÔ∏è Uploading to Hive images...");
      const hiveUrl = await uploadImage(thumbnailFile, signature);
      console.log("üéâ Thumbnail uploaded successfully:", hiveUrl);

      setThumbnailUrl(hiveUrl);
      setIsGeneratingThumbnail(false);
      return hiveUrl;
    } catch (error) {
      console.error("‚ùå Error generating/uploading thumbnail:", error);
      setIsGeneratingThumbnail(false);
      return null;
    }
  };

  // Handle thumbnail capture
  const handleCaptureFrame = async () => {
    console.log("üñ±Ô∏è User clicked capture frame");
    await generateThumbnail();
  };

  // Handle slider interaction end
  const handleSliderChangeEnd = () => {
    console.log("üîö Slider interaction ended");
    setIsPreviewingSlider(false);
    setIsDragging(false);
  };

  // Create trimmed video blob - SIMPLIFIED APPROACH
  const createTrimmedVideo = async (
    file: File,
    start: number,
    end: number
  ): Promise<Blob> => {
    console.log("‚úÇÔ∏è Creating trimmed video (SIMPLE):", {
      start,
      end,
      duration: end - start,
      fileName: file.name,
    });

    return new Promise((resolve, reject) => {
      // Create video element
      const video = document.createElement("video");
      video.crossOrigin = "anonymous";
      video.preload = "metadata";

      const fileUrl = URL.createObjectURL(file);
      video.src = fileUrl;

      console.log("üîó Video created with URL:", fileUrl);

      video.onloadedmetadata = async () => {
        try {
          console.log(
            "üìä Video loaded, dimensions:",
            video.videoWidth,
            "x",
            video.videoHeight
          );
          console.log("üìä Video duration:", video.duration);

          // Create canvas for recording
          const canvas = document.createElement("canvas");
          const ctx = canvas.getContext("2d");

          if (!ctx) {
            throw new Error("Could not get canvas context");
          }

          // Set canvas size to match video
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;

          console.log("üé® Canvas ready:", canvas.width, "x", canvas.height);

          // Create MediaRecorder from canvas stream
          const stream = canvas.captureStream(30); // 30 FPS
          const mediaRecorder = new MediaRecorder(stream, {
            mimeType: "video/webm;codecs=vp9",
            videoBitsPerSecond: 2500000, // 2.5 Mbps
          });

          const chunks: Blob[] = [];

          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              chunks.push(event.data);
              console.log("üì¶ Chunk recorded:", event.data.size, "bytes");
            }
          };

          mediaRecorder.onstop = () => {
            console.log("üõë Recording complete, chunks:", chunks.length);
            const blob = new Blob(chunks, { type: "video/webm" });
            console.log("üé• Final blob size:", blob.size);
            URL.revokeObjectURL(fileUrl);
            resolve(blob);
          };

          // **THE SIMPLE SOLUTION**
          // Seek to start, record frames at natural video speed
          video.currentTime = start;

          video.onseeked = () => {
            console.log("üéØ Seeked to start:", start);

            // Start recording
            mediaRecorder.start();
            console.log("ÔøΩ Recording started");

            // Set playback rate to 1.0 (normal speed)
            video.playbackRate = 1.0;

            // Play the video segment
            video
              .play()
              .then(() => {
                console.log("‚ñ∂Ô∏è Video playing at normal speed");

                // Draw frames continuously
                const renderFrame = () => {
                  if (video.currentTime >= end) {
                    console.log("‚èπÔ∏è Reached end time, stopping");
                    video.pause();
                    mediaRecorder.stop();
                    return;
                  }

                  if (!video.paused && !video.ended) {
                    // Draw current frame to canvas
                    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                    requestAnimationFrame(renderFrame);
                  }
                };

                // Start rendering frames
                requestAnimationFrame(renderFrame);
              })
              .catch((error) => {
                console.error("‚ùå Play failed:", error);
                reject(error);
              });
          };

          // Backup stop mechanism
          video.ontimeupdate = () => {
            if (video.currentTime >= end) {
              console.log("üõë Time update stop triggered");
              video.pause();
              mediaRecorder.stop();
            }
          };
        } catch (error) {
          console.error("‚ùå Setup error:", error);
          URL.revokeObjectURL(fileUrl);
          reject(error);
        }
      };

      video.onerror = (error) => {
        console.error("‚ùå Video load error:", error);
        URL.revokeObjectURL(fileUrl);
        reject(new Error("Failed to load video"));
      };
    });
  };

  // Handle trimming
  const handleTrim = async () => {
    if (!videoFile || !videoRef.current) {
      console.log("‚ùå Cannot trim: missing videoFile or videoRef");
      return;
    }

    console.log("‚úÇÔ∏è Starting trim process...");
    setIsProcessing(true);

    try {
      console.log("üé¨ Creating trimmed video...");
      const trimmedBlob = await createTrimmedVideo(
        videoFile,
        startTime,
        endTime
      );
      console.log("‚úÖ Trimmed video created, size:", trimmedBlob.size);

      let finalThumbnailUrl = thumbnailUrl;
      if (!finalThumbnailUrl) {
        console.log("üì∏ No thumbnail exists, generating one...");
        const middleTime = startTime + (endTime - startTime) / 2;
        videoRef.current.currentTime = middleTime;
        await new Promise((resolve) => setTimeout(resolve, 100));
        finalThumbnailUrl = await generateThumbnail();
      } else {
        console.log("‚úÖ Using existing thumbnail:", finalThumbnailUrl);
      }

      const trimmedFile = new File([trimmedBlob], `trimmed_${videoFile.name}`, {
        type: videoFile.type,
      });
      console.log("üìÅ Trimmed file created:", {
        name: trimmedFile.name,
        size: trimmedFile.size,
        type: trimmedFile.type,
      });

      // Attach thumbnail URL to file
      (trimmedFile as any).thumbnailUrl = finalThumbnailUrl;
      console.log("üîó Attached thumbnail URL to file:", finalThumbnailUrl);

      console.log("üöÄ Calling onTrimComplete with trimmed file");
      onTrimComplete(trimmedFile);
      onClose();
    } catch (error) {
      console.error("‚ùå Error trimming video:", error);
      alert("Failed to trim video. Please try again.");
    } finally {
      setIsProcessing(false);
    }
  };

  // Handle bypass (skip trimming)
  const handleBypass = async () => {
    if (videoFile) {
      console.log("‚è≠Ô∏è Bypassing trim, using original file:", videoFile.name);
      try {
        let finalThumbnailUrl = thumbnailUrl;
        if (!finalThumbnailUrl) {
          console.log("üì∏ No thumbnail exists, generating one for bypass...");
          if (videoRef.current) {
            videoRef.current.currentTime = duration / 2;
            await new Promise((resolve) => setTimeout(resolve, 100));
            finalThumbnailUrl = await generateThumbnail();
          }
        } else {
          console.log(
            "‚úÖ Using existing thumbnail for bypass:",
            finalThumbnailUrl
          );
        }

        // Attach thumbnail URL to original file
        (videoFile as any).thumbnailUrl = finalThumbnailUrl;
        console.log(
          "üîó Attached thumbnail URL to original file:",
          finalThumbnailUrl
        );

        console.log("üöÄ Calling onTrimComplete with original file");
        onTrimComplete(videoFile);
        onClose();
      } catch (error) {
        console.error("‚ùå Error generating thumbnail for bypass:", error);
        console.log("‚ö†Ô∏è Proceeding without thumbnail");
        onTrimComplete(videoFile);
        onClose();
      }
    }
  };

  const isValidSelection =
    endTime - startTime <= maxDuration && endTime - startTime > 0;
  const selectedDuration = endTime - startTime;

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      if (seekTimeoutRef.current) {
        clearTimeout(seekTimeoutRef.current);
        seekTimeoutRef.current = null;
      }
    };
  }, []);

  // Debug modal state
  useEffect(() => {
    console.log("üé≠ VideoTrimModal state:", {
      isOpen,
      hasVideoFile: !!videoFile,
      hasVideoUrl: !!videoUrl,
      duration,
      startTime,
      endTime,
      isValidSelection,
      canBypass,
      isProcessing,
    });
  }, [
    isOpen,
    videoFile,
    videoUrl,
    duration,
    startTime,
    endTime,
    isValidSelection,
    canBypass,
    isProcessing,
  ]);

  return (
    <Modal
      isOpen={isOpen}
      onClose={onClose}
      size={{ base: "full", md: "xl" }}
      onCloseComplete={() => {
        console.log("üßπ Modal close complete, cleaning up state");
        setVideoUrl(null);
        setIsPlaying(false);
        setThumbnailBlob(null);
        setThumbnailUrl(null);
        setIsGeneratingThumbnail(false);
      }}
      closeOnOverlayClick={false}
      motionPreset="slideInBottom"
      trapFocus={true}
      autoFocus={false}
    >
      <ModalOverlay bg="blackAlpha.600" />
      <ModalContent
        bg={"background"}
        maxH={{ base: "100vh", md: "90vh" }}
        overflowY="auto"
        mx={{ base: 0, md: 4 }}
        my={{ base: 0, md: 4 }}
      >
        <ModalHeader pb={{ base: 2, md: 4 }}>
          <VStack align="start" spacing={2}>
            <Text fontSize={{ base: "lg", md: "xl" }}>
              Trim Video - Max {maxDuration} seconds
            </Text>
            {canBypass ? (
              <Text fontSize="sm" color="primary">
                ‚ú® You have {">"}100 HP - You can bypass this limit
              </Text>
            ) : (
              <Text fontSize="sm" color="accent">
                üìπ Videos are limited to {maxDuration} seconds in the feed. Get{" "}
                {">"}100 HP to bypass this limit.
              </Text>
            )}
          </VStack>
        </ModalHeader>
        <ModalCloseButton />

        <ModalBody px={{ base: 3, md: 6 }} py={{ base: 3, md: 4 }}>
          <VStack spacing={{ base: 3, md: 4 }}>
            {/* Video Player - Always at the top */}
            {videoUrl && (
              <VideoPlayer
                videoRef={videoRef}
                videoUrl={videoUrl}
                isPlaying={isPlaying}
                onLoadedMetadata={handleLoadedMetadata}
                onTimeUpdate={handleTimeUpdate}
                onTogglePlayPause={togglePlayPause}
              />
            )}

            {/* Duration Info */}
            <Alert status={isValidSelection ? "success" : "warning"} size="sm">
              <AlertIcon />
              <Text fontSize="sm">
                Original: {formatTime(duration)} | Selected:{" "}
                {formatTime(selectedDuration)}
                {isValidSelection ? " ‚úì" : ` ‚ö†Ô∏è Exceeds ${maxDuration}s`}
              </Text>
            </Alert>

            {/* Tabs for Trim and Thumbnail functionality */}
            <Tabs width="100%" variant="enclosed" colorScheme="blue">
              <TabList>
                <Tab>‚úÇÔ∏è Trim Video</Tab>
                <Tab>üì∏ Thumbnail</Tab>
              </TabList>

              <TabPanels>
                {/* Trim Tab */}
                <TabPanel px={0}>
                  <VideoTimeline
                    duration={duration}
                    currentTime={currentTime}
                    startTime={startTime}
                    endTime={endTime}
                    isValidSelection={isValidSelection}
                    maxDuration={maxDuration}
                    onSeek={seekTo}
                    onStartTimeChange={setStartTime}
                    onEndTimeChange={setEndTime}
                    onDragStart={() => {
                      console.log("üîÑ Drag started");
                      setIsPreviewingSlider(true);
                      setIsDragging(true);
                    }}
                    onDragEnd={handleSliderChangeEnd}
                  />
                </TabPanel>

                {/* Thumbnail Tab */}
                <TabPanel px={0}>
                  <ThumbnailCapture
                    thumbnailUrl={thumbnailUrl}
                    isGeneratingThumbnail={isGeneratingThumbnail}
                    onCaptureFrame={handleCaptureFrame}
                  />
                </TabPanel>
              </TabPanels>
            </Tabs>
          </VStack>
        </ModalBody>

        <VideoTrimModalFooter
          isValidSelection={isValidSelection}
          maxDuration={maxDuration}
          canBypass={canBypass}
          isProcessing={isProcessing}
          onClose={onClose}
          onBypass={handleBypass}
          onTrim={handleTrim}
        />
      </ModalContent>
    </Modal>
  );
};

export default VideoTrimModal;
